{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "98a8f46d",
   "metadata": {},
   "source": [
    "Time-Series Model.\n",
    "\n",
    "Transform the provided record-level dataset into a time-series model. The main objective of this model is to gain insights into the temporal patterns of vehicle listings, with a particular emphasis on conducting an inventory analysis over time, segmented by regions. For instance, the model should facilitate the creation of a time-series chart that represents the number of available vehicles over time, filtered by specific criteria such as region, vehicle type, etc. This will aid in understanding regional demand-supply dynamics, seasonal trends, and other relevant insights."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db6c922d",
   "metadata": {},
   "source": [
    "Step 1:\n",
    "I will import the necessary packages, handle missing values, drop unnecessary columns, and convert the \"posting_date\" to a datetime data type.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f1f6409",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load all the neccessary packages that i will use in the notebook. \n",
    "\n",
    "import pytz\n",
    "import warnings\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b95042cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dataset into my notebook\n",
    "data_path = \"C:\\\\Users\\\\Francis Mwangi\\\\Desktop\\\\craigslist_vehicles.csv\"\n",
    "data = pd.read_csv(data_path)\n",
    "\n",
    "#preview the first 5 rows of 'craigslist_vehicles.csv' dataset\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "396013d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#list the columns i have in my dataframe\n",
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2d0cde6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if columns exist before dropping\n",
    "columns_to_drop = ['Unnamed: 0', 'url', 'region_url', 'VIN', 'image_url', 'description', 'county', 'lat', 'long', 'removal_date']\n",
    "\n",
    "# filter the columns to drop only those that exist in the DataFrame\n",
    "columns_to_drop_existing = [col for col in columns_to_drop if col in data.columns]\n",
    "\n",
    "# drop the existing columns\n",
    "data = data.drop(columns=columns_to_drop_existing)\n",
    "\n",
    "\n",
    "# convert 'posting_date' to datetime data type\n",
    "data['posting_date'] = pd.to_datetime(data['posting_date'],  utc=True)\n",
    "\n",
    "\n",
    "#preview the first 5 rows of 'craigslist_vehicles.csv' dataset after droping unncessary columns and coverting \"post)time\" to date. \n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76a5d97d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check column data type\n",
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd9d9c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check rows and columns\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d924676",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check for the missing Values\n",
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9cff6df",
   "metadata": {},
   "outputs": [],
   "source": [
    "#chech the datatype\n",
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ad8b165",
   "metadata": {},
   "outputs": [],
   "source": [
    "# then i handle missing values: I fill the numeric ones with mean and categorical ones with mode. \n",
    "def handle_missing_values(data):\n",
    "    # fill missing numerical values with mean\n",
    "    numerical_columns = ['year', 'odometer']\n",
    "    data[numerical_columns] = data[numerical_columns].fillna(data[numerical_columns].mean())\n",
    "\n",
    "    # fill missing categorical values with mode\n",
    "    categorical_columns = ['manufacturer', 'model', 'condition', 'cylinders', 'fuel', 'title_status',\n",
    "                           'transmission', 'drive', 'size', 'type', 'paint_color', 'posting_date']\n",
    "    data[categorical_columns] = data[categorical_columns].apply(lambda x: x.fillna(x.mode().iloc[0]))\n",
    "\n",
    "    return data\n",
    "\n",
    "data = handle_missing_values(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43366756",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check if their is any missing values remaining (forgotten)\n",
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8de36960",
   "metadata": {},
   "outputs": [],
   "source": [
    "#list columns in my \"clean\" data frame\n",
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ac7f0e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check the datatye after cleaning \n",
    "data.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae85446d",
   "metadata": {},
   "source": [
    "Step 2:\n",
    "\n",
    "After successfully handling missing values and cleaning the data i willl move to the next step where i will aggregate the data based on the \"posting_date,\" \"region,\" and \"type\" of vehicle, to be able to analyze the temporal patterns, seasonal trends, and demand-supply dynamics.\n",
    "\n",
    "This will allow me to perform various analyses and gain insights into how the inventory varies over time in different regions and vehicle types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aca1c9c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_tz_aware(posting_date):\n",
    "    if not posting_date.tzinfo:\n",
    "        return posting_date.replace(tzinfo=pytz.utc)\n",
    "    else:\n",
    "        return posting_date\n",
    "\n",
    "data['posting_date'] = data['posting_date'].apply(convert_to_tz_aware)\n",
    "\n",
    "data_agg = data.groupby(['region', 'type', 'posting_date']).size().reset_index(name='count')\n",
    "\n",
    "data_agg = data_agg.sort_values(by='posting_date')\n",
    "\n",
    "data_agg.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8854517",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an interactive time-series chart\n",
    "fig = px.line(data_agg, x='posting_date', y='count', color='region', line_group='type',\n",
    "              title='Number of Available Vehicles Over Time by Region and Vehicle Type',\n",
    "              labels={'count': 'Number of Vehicles'})\n",
    "\n",
    "# Customize the layout\n",
    "fig.update_layout(\n",
    "    xaxis_title='Posting Date',\n",
    "    yaxis_title='Number of Vehicles',\n",
    "    hovermode='x',\n",
    "    showlegend=True,\n",
    ")\n",
    "\n",
    "# Show the chart\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99c933d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# group the data by day and count the number of listings\n",
    "data_freq = data_agg.groupby(pd.Grouper(key='posting_date', freq='D')).sum().reset_index()\n",
    "\n",
    "# create the time frequency graph\n",
    "fig_freq = go.Figure(data=go.Bar(\n",
    "    x=data_freq['posting_date'],\n",
    "    y=data_freq['count'],\n",
    "    marker_color='royalblue',\n",
    "    opacity=0.8\n",
    "))\n",
    "\n",
    "# customize the layout\n",
    "fig_freq.update_layout(\n",
    "    title='Time Frequency Graph: Number of Vehicle Listings per Day',\n",
    "    xaxis_title='Posting Date',\n",
    "    yaxis_title='Number of Vehicle Listings',\n",
    "    xaxis_tickangle=-45,\n",
    ")\n",
    "\n",
    "# show the time frequency graph\n",
    "fig_freq.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d8f9fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform seasonal decomposition\n",
    "data_agg = data_agg.set_index('posting_date')\n",
    "result = seasonal_decompose(data_agg['count'], model='additive', period=365)\n",
    "\n",
    "# create a new DataFrame to store the decomposition components\n",
    "decomposed_data = pd.DataFrame({\n",
    "    'trend': result.trend,\n",
    "    'seasonal': result.seasonal,\n",
    "    'residual': result.resid,\n",
    "})\n",
    "\n",
    "# reset the index for plotting\n",
    "decomposed_data = decomposed_data.reset_index()\n",
    "\n",
    "# plot the seasonal decomposition\n",
    "fig_decompose = go.Figure()\n",
    "\n",
    "fig_decompose.add_trace(go.Scatter(x=decomposed_data['posting_date'], y=decomposed_data['trend'],\n",
    "                                   mode='lines', name='Trend'))\n",
    "fig_decompose.add_trace(go.Scatter(x=decomposed_data['posting_date'], y=decomposed_data['seasonal'],\n",
    "                                   mode='lines', name='Seasonal'))\n",
    "fig_decompose.add_trace(go.Scatter(x=decomposed_data['posting_date'], y=decomposed_data['residual'],\n",
    "                                   mode='lines', name='Residual'))\n",
    "\n",
    "# customize the layout\n",
    "fig_decompose.update_layout(title='Seasonal Decomposition of Time Series',\n",
    "                            xaxis_title='Posting Date',\n",
    "                            yaxis_title='Counts',\n",
    "                            showlegend=True)\n",
    "\n",
    "# show the plot\n",
    "fig_decompose.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04b18c51",
   "metadata": {},
   "source": [
    "Explanation:\n",
    "\n",
    "In the plot displayed above, the trend and seasonality are not discernible; only the residual component is visible. This is primarily due to the limited time period over which the data was collected, making it challenging to capture and observe the underlying seasonal and trend patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2832abfc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
